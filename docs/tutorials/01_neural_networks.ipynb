{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brilliant-cross",
   "metadata": {},
   "source": [
    "# Quantum Neural Networks\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates different quantum neural network (QNN) implementations provided in `qiskit-machine-learning`, and how they can be integrated into basic quantum machine learning (QML) workflows.\n",
    "\n",
    "The tutorial is structured as follows:\n",
    "1. [Introduction](#Introduction)\n",
    "2. [How to Instantiate QNNs](#Instantiate)\n",
    "3. [How to Run a Forward Pass](#Forward)\n",
    "4. [How to Run a Backward Pass](#Backward)\n",
    "5. [Advanced Funtionality](#Advanced)\n",
    "6. [Conclusion](#Conclusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f47d2070",
   "metadata": {},
   "source": [
    "<a id='Introduction'></a>\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1. Quantum vs. Classical Neural Networks\n",
    "\n",
    "Classical neural networks are algorithmic models inspired by the human brain that can be trained to recognize patterns in data and learn to solve complex problems. They are based in a series of interconnected nodes, or *neurons*, organized in a layered structure, with parameters that can be learned by applying machine or deep learning training strategies.  \n",
    "\n",
    "The motivation behind quantum machine learning (QML) is to integrate notions from quantum computing and classical machine learning to open the way for new and improved learning schemes. QNNs apply this generic principle by combining classical neural networks and parametrized quantum circuits. Because they lie at an intersection between two fields, QNNs can be viewed under two perspectives:\n",
    "\n",
    "- From a **machine learning perspective**, QNNs are, once again, algorithmic models that can be trained to find hidden patterns in data in a similar manner to their classical counterparts (through backpropagation). These models are parametrized, and perform **data loading** with **input** parameters, and a **data processing** with trainable **weights**. \n",
    "\n",
    "- From a **quantum computing perspective**, QNNs are quantum algorithms based on parametrized quantum circuits that can be trained in a variational manner using classical optimizers. These circuits contain a **feature map** (with input parameters) and an **ansatz** (with trainable weights).\n",
    "\n",
    "As you can see, these two perspectives are complementary, and do not necessarily rely on strict definitions of concepts such as \"quantum neuron\" or what constitutes a \"layer\". \n",
    "\n",
    "### 1.2. Implementation in `qiskit-machine-learning`\n",
    "\n",
    "The QNNs in `qiskit-machine-learning` are meant as application-agnostic computational units that can be used for different use cases, and their setup will depend on the application they are needed for. The module contains an interface of the QNNs and two specific implementations:\n",
    "\n",
    "1. [NeuralNetwork](https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.NeuralNetwork.html): The interface for neural networks. This is an abstract class all QNNs inherit from.\n",
    "2. [EstimatorQNN](https://qiskit.org/documentation/machine-learning/stubs/qiskit_machine_learning.neural_networks.EstimatorQNN.html): A network based on the evaluation of quantum mechanical observables.\n",
    "3. [SamplerQNN](https://qiskit.org/documentation/machine-learning/locale/fr_FR/stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html): A network based on the samples resulting from measuring a quantum circuit.\n",
    "\n",
    "These implementations are based on the [qiskit primitives](https://qiskit.org/documentation/apidoc/primitives.html). The primitives are the entry point to run QNNs on either a simulator or real quantum hardware. Each implementation, `EstimatorQNN` and `SamplerQNN`, takes in an optional instance of their corresponding primitive, which can be any subclass of `BaseEstimator` and `BaseSampler` respectively.  \n",
    "\n",
    "The `qiskit.primitives` module provides a reference implementation for the `Sampler` and `Estimator` classes tu run statevector simulations. By default, if no instance is passed to a QNN class, an instance of the corresponding reference primitive (`Sampler` or `Estimator`) is created automatically by the network. \n",
    "For more information about primitives please refer to the [primitives documentation](https://qiskit.org/documentation/apidoc/primitives.html).\n",
    "\n",
    "The `NeuralNetwork` class is the interface for all QNNs available in `qiskit-machine-learning`.\n",
    "It exposes a forward and a backward pass that take data samples and trainable weights as input.\n",
    "\n",
    "It's important to note that `NeuralNetwork`s are \"stateless\". They do not contain any training capabilities, these are pushed to the actual algorithms or applications ([classifiers](https://qiskit.org/documentation/machine-learning/apidocs/qiskit_machine_learning.algorithms.html#classifiers), [regressors](https://qiskit.org/documentation/machine-learning/apidocs/qiskit_machine_learning.algorithms.html#regressors), etc), nor do they store the values for trainable weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba316207",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Let's now look into specific examples for the two `NeuralNetwork` implementations. But before, let's set up the algorithmic seed to ensure that the results don't change between runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "annual-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.utils import algorithm_globals\n",
    "\n",
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-uniform",
   "metadata": {},
   "source": [
    "<a id='Instantiate'></a>\n",
    "## 2. How to Instantiate QNNs\n",
    "\n",
    "### 2.1. `EstimatorQNN`\n",
    "\n",
    "The `EstimatorQNN` takes in a parametrized quantum circuit as input, as well as an optional quantum mechanical observable, and outputs expectation value computations for the forward pass. \n",
    "\n",
    "The quantum circuit's parameters can be used to load classical data (feature map) as well as represent trainable weights (ansatz). The observable allows to define custom loss functions for advanced QNN training strategies. The `EstimatorQNN` also accepts lists of observables to construct more complex QNNs.\n",
    "\n",
    "Let's see an `EstimatorQNN` in action with a simple example. We start by constructing the parametrized circuit. This quantum circuit has two parameters, one represents a QNN input and the other represents a trainable weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "popular-artwork",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 352.675x117.056 with 1 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit.circuit import Parameter\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "params1 = [Parameter(\"input1\"), Parameter(\"weight1\")]\n",
    "qc1 = QuantumCircuit(1)\n",
    "qc1.h(0)\n",
    "qc1.ry(params1[0], 0)\n",
    "qc1.rx(params1[1], 0)\n",
    "qc1.draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-aquatic",
   "metadata": {},
   "source": [
    "We can now create an observable to define the expectation value computation. If not set, then the `EstimatorQNN` will automatically create the default observable $Z^{\\otimes n}$. Here, $n$ is the number of qubits of the quantum circuit.\n",
    "\n",
    "In this example, we will change things up and use the $Y^{\\otimes n}$ observable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "encouraging-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "observable1 = SparsePauliOp.from_list([(\"Y\" * qc1.num_qubits, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1fb7ea",
   "metadata": {},
   "source": [
    "Together with the quantum circuit defined above, and the observable we have created, the `EstimatorQNN` constructor takes in the following keyword arguments:\n",
    "\n",
    "- `estimator`: optional primitive instance \n",
    "- `input_params`: list of parameters from que quantum circuit that should be treated as \"network inputs\"\n",
    "- `weight_params`: list of parameters from que quantum circuit that should be treated as \"network weights\"\n",
    "\n",
    "In this example, we previously decided that the first parameter of `params1` should be the input, while the second should be the weight. We will not set the `estimator` parameter, the network will create an instance of the reference `Estimator` primitive for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italian-clear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.neural_networks.estimator_qnn.EstimatorQNN at 0x7f9518737ee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "\n",
    "estimator_qnn = EstimatorQNN(\n",
    "    circuit=qc1, \n",
    "    observables=observable1, \n",
    "    input_params=[params1[0]], \n",
    "    weight_params=[params1[1]]\n",
    ")\n",
    "estimator_qnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ecacdb",
   "metadata": {},
   "source": [
    "Now, our QNN is ready to perform some backward and forward passes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac3811",
   "metadata": {},
   "source": [
    "### 2.2. `SamplerQNN`\n",
    "\n",
    "The `SamplerQNN` is instantiated in a similar way to the `EstimatorQNN`, but because it directly returns samples from measuring the quantum circuit, it does not require a custom observable. \n",
    "\n",
    "These output samples are interpreted by default as probabilities of measuring the integer index corresponding to a bitstring. However, the `SamplerQNN` also allows to specify an `interpret` function to post-process the samples. This function should be defined so that it takes a measured integer (from a bitstring) and map it to a new value, i.e. non-negative integer. \n",
    "\n",
    "**(!)** It's important to note that if a custom `interpret` function is defined, the `output_shape` cannot be inferred by the class, and **needs to be provided explicitly**. \n",
    "\n",
    "**(!)** It's also important to keep in mind that if no `interpret` function is used, the dimension of the probability vector will scale exponentially with the number of qubits. With a custom `interpret` function, this scaling can change. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, the result will be a probability vector of length 2 independently of the number of qubits. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc2353",
   "metadata": {},
   "source": [
    "Let's have a look at `SamplerQNN` by first designing a simple quantum parameterized circuit using [RealAmplitudes](https://qiskit.org/documentation/stubs/qiskit.circuit.library.RealAmplitudes.html). `RealAmplitudes` consists of a quantum circuit with alternating layers of Y rotations and CX entanglements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acceptable-standing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 370.906x200.667 with 1 Axes>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit.circuit.library import RealAmplitudes\n",
    "\n",
    "qc2 = RealAmplitudes(2, entanglement=\"linear\", reps=1)\n",
    "qc2.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86defb",
   "metadata": {},
   "source": [
    "This circuit contains four parameters, so we can assign the first three as inputs, and the last parameter as trainable weight, and give this information to the `SamplerQNN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c007d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.neural_networks.sampler_qnn.SamplerQNN at 0x7f953864ba30>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "\n",
    "sampler_qnn = SamplerQNN(circuit=qc2, \n",
    "                         input_params=qc2.parameters[:3], \n",
    "                         weight_params=qc2.parameters[3:])\n",
    "sampler_qnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe6b8be",
   "metadata": {},
   "source": [
    "Please note that once again, we are choosing not to send the `Sampler` instance to the QNN and relying on the default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac89b99",
   "metadata": {},
   "source": [
    "<a id='Forward'></a>\n",
    "## 3. How to Run a Forward Pass\n",
    "\n",
    "In a real setting, the inputs would be defined by the dataset, and the weights would be defined by the training algorithm or as part of a pre-trained model. However, for the sake of this tutorial, we will specify random sets of input and weights of the right dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beneficial-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator QNN Example\n",
    "input_estimator = algorithm_globals.random.random(estimator_qnn.num_inputs)\n",
    "weights_estimator = algorithm_globals.random.random(estimator_qnn.num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d5c27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features for EstimatorQNN: 1 \n",
      "Input: [0.77395605]\n",
      "Number of trainable weights for EstimatorQNN: 1 \n",
      "Weights: [0.43887844]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of input features for EstimatorQNN: {estimator_qnn.num_inputs} \\nInput: {input_estimator}\")\n",
    "print(f\"Number of trainable weights for EstimatorQNN: {estimator_qnn.num_weights} \\nWeights: {weights_estimator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0fd6253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sampler QNN Example\n",
    "input_sampler = algorithm_globals.random.random(sampler_qnn.num_inputs)\n",
    "weights_sampler = algorithm_globals.random.random(sampler_qnn.num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a008cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features for SamplerQNN: 3 \n",
      "Input: [0.85859792 0.69736803 0.09417735]\n",
      "Number of trainable weights for SamplerQNN: 1 \n",
      "Weights: [0.97562235]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of input features for SamplerQNN: {sampler_qnn.num_inputs} \\nInput: {input_sampler}\")\n",
    "print(f\"Number of trainable weights for SamplerQNN: {sampler_qnn.num_weights} \\nWeights: {weights_sampler}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1500df",
   "metadata": {},
   "source": [
    "Once we have the inputs and the weights, let's see the results for batched and unbatched passes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e7302",
   "metadata": {},
   "source": [
    "### 3.1. Unbatched Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fba01a3",
   "metadata": {},
   "source": [
    "For the `EstimatorQNN`, the expected output shape for the forward pass is `(1, num_qubits * num_observables)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54bed89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output shape for EstimatorQNN: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "forward_estimator = estimator_qnn.forward(input_estimator, weights_estimator)\n",
    "\n",
    "print(f\"Forward output shape for EstimatorQNN: {forward_estimator.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94473b35",
   "metadata": {},
   "source": [
    "For the `SamplerQNN` (without custom interpret function), the expected output shape for the forward pass is `(1, 2**num_qubits)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb847a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output shape for SamplerQNN: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "forward_sampler = sampler_qnn.forward(input_sampler, weights_sampler)\n",
    "\n",
    "print(f\"Forward output shape for SamplerQNN: {forward_sampler.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c843c95",
   "metadata": {},
   "source": [
    "### 3.2. Batched Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612ff46",
   "metadata": {},
   "source": [
    "For the `EstimatorQNN`, the expected output shape for the forward pass is `(batch_size, num_qubits * num_observables)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2629892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output shape for EstimatorQNN: (2, 1)\n"
     ]
    }
   ],
   "source": [
    "forward_estimator_batched = estimator_qnn.forward([input_estimator, input_estimator], weights_estimator)\n",
    "\n",
    "print(f\"Forward output shape for EstimatorQNN: {forward_estimator_batched.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7b7bb",
   "metadata": {},
   "source": [
    "For the `SamplerQNN` (without custom interpret function), the expected output shape for the forward pass is `(batch_size, 2**num_qubits)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29eb2151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output shape for SamplerQNN: (2, 4)\n"
     ]
    }
   ],
   "source": [
    "forward_sampler_batched = sampler_qnn.forward([input_sampler, input_sampler], weights_sampler)\n",
    "\n",
    "print(f\"Forward output shape for SamplerQNN: {forward_sampler_batched.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b8ee1",
   "metadata": {},
   "source": [
    "<a id='Backward'></a>\n",
    "## 4. How to Run a Backward Pass\n",
    "\n",
    "Let's take advantage of the inputs and weights defined above to show how the backward pass works. This pass returns a tuple `(input_gradients, weight_gradients)`. By default, the backward pass will only calculate gradients with respect to the weight parameters. If you want to enable gradients with respect to the input parameters, you should set the following flag during the QNN instantiation:\n",
    "\n",
    "```python\n",
    "qnn = ...QNN(..., input_gradients=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b90338",
   "metadata": {},
   "source": [
    "### 4.1. Backward Pass without Input Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c9700",
   "metadata": {},
   "source": [
    "For the `EstimatorQNN`, the expected output shape for the weight gradients is: `(batch_size, num_qubits * num_observables, num_weights)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "entitled-reaction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradients shape for EstimatorQNN: None\n",
      "Weight gradients shape for EstimatorQNN: (1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "input_grad_e, weight_grad_e = estimator_qnn.backward(input_estimator, weights_estimator)\n",
    "\n",
    "print(f\"Input gradients shape for EstimatorQNN: {input_grad_e}\")\n",
    "print(f\"Weight gradients shape for EstimatorQNN: {weight_grad_e.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebaa404",
   "metadata": {},
   "source": [
    "For the `SamplerQNN` (without custom interpret function), the expected output shape for the forward pass is `(batch_size, 2**num_qubits, num_weights)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eefacefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradients shape for SamplerQNN: None\n",
      "Weight gradients shape for SamplerQNN: (1, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "input_grad_s, weight_grad_s = sampler_qnn.backward(input_sampler, weights_sampler)\n",
    "\n",
    "print(f\"Input gradients shape for SamplerQNN: {input_grad_s}\")\n",
    "print(f\"Weight gradients shape for SamplerQNN: {weight_grad_s.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d28a00",
   "metadata": {},
   "source": [
    "### 4.2. Backward Pass with Input Gradients\n",
    "\n",
    "Let's enable the `input_gradients` to show what the expected output sizes are for this option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ccc4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_qnn.input_gradients = True\n",
    "sampler_qnn.input_gradients = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ebc80",
   "metadata": {},
   "source": [
    "For the `EstimatorQNN`, the expected output shape for the input gradients is: `(batch_size, num_qubits * num_observables, num_inputs)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4332f42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradients shape for EstimatorQNN: (1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "input_grad_e, weight_grad_e = estimator_qnn.backward(input_estimator, weights_estimator)\n",
    "\n",
    "print(f\"Input gradients shape for EstimatorQNN: {input_grad_e.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76da18a",
   "metadata": {},
   "source": [
    "For the `SamplerQNN` (without custom interpret function), the expected output shape for the forward pass is `(batch_size, 2**num_qubits, num_inputs)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3339f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gradients shape for SamplerQNN: (1, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "input_grad_s, weight_grad_s = sampler_qnn.backward(input_sampler, weights_sampler)\n",
    "\n",
    "print(f\"Input gradients shape for SamplerQNN: {input_grad_s.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45871b6d",
   "metadata": {},
   "source": [
    "<a id='Advanced'></a>\n",
    "## 5. Advanced Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fb829",
   "metadata": {},
   "source": [
    "### 5.1. `EstimatorQNN` with Multiple Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c86fd7",
   "metadata": {},
   "source": [
    "The `EstimatorQNN` allows to pass lists of observables for more complex QNN architectures. For example (note the change in output shape):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e1e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "observable2 = SparsePauliOp.from_list([(\"Z\" * qc1.num_qubits, 1)])\n",
    "\n",
    "estimator_qnn2 = EstimatorQNN(\n",
    "                circuit=qc1,\n",
    "                observables=[observable1, observable2],\n",
    "                input_params=[params1[0]],\n",
    "                weight_params=[params1[1]],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e801632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output for EstimatorQNN1: (1, 1)\n",
      "Forward output for EstimatorQNN2: (1, 2)\n",
      "Backward output for EstimatorQNN1: (1, 1, 1)\n",
      "Backward output for EstimatorQNN2: (1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "forward_estimator2 = estimator_qnn2.forward(input_estimator, weights_estimator)\n",
    "input_grad_e2, weight_grad_e2 = estimator_qnn2.backward(input_estimator, weights_estimator)\n",
    "\n",
    "print(f\"Forward output for EstimatorQNN1: {forward_estimator.shape}\")\n",
    "print(f\"Forward output for EstimatorQNN2: {forward_estimator2.shape}\")\n",
    "print(f\"Backward output for EstimatorQNN1: {weight_grad_e.shape}\")\n",
    "print(f\"Backward output for EstimatorQNN2: {weight_grad_e2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ec9f1",
   "metadata": {},
   "source": [
    "### 5.2. `SamplerQNN` with custom `interpret`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ef3ba",
   "metadata": {},
   "source": [
    "One common `interpret` method for `SamplerQNN` is the `parity` function, that allows to perform binary classification. As explained in the instantiation section, the use of interpret functions will modify the output shape of the forward and backward passes (`output_shape` instead of `2**num_qubits`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eed68d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parity = lambda x: \"{:b}\".format(x).count(\"1\") % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "sampler_qnn2 = SamplerQNN(circuit=qc2, \n",
    "                         input_params=qc2.parameters[:3], \n",
    "                         weight_params=qc2.parameters[3:],\n",
    "                         interpret = parity,\n",
    "                        output_shape = output_shape\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2888195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output for SamplerQNN1: (1, 4)\n",
      "Forward output for SamplerQNN2: (1, 2)\n",
      "Backward output for SamplerQNN1: (1, 4, 1)\n",
      "Backward output for SamplerQNN2: (1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "forward_sampler2 = sampler_qnn2.forward(input_sampler, weights_sampler)\n",
    "input_grad_s2, weight_grad_s2 = sampler_qnn2.backward(input_sampler, weights_sampler)\n",
    "\n",
    "print(f\"Forward output for SamplerQNN1: {forward_sampler.shape}\")\n",
    "print(f\"Forward output for SamplerQNN2: {forward_sampler2.shape}\")\n",
    "print(f\"Backward output for SamplerQNN1: {weight_grad_s.shape}\")\n",
    "print(f\"Backward output for SamplerQNN2: {weight_grad_s2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66117e82",
   "metadata": {},
   "source": [
    "<a id='Conclusion'></a>\n",
    "## 6. Conclusion\n",
    "In this tutorial, we learn about the two neural networks provided by Qiskit Machine Learning, namely `EstimatorQNN` and `SamplerQNN`, which extend the base `NeuralNetwork` class.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit.tools.jupyter\n",
    "\n",
    "%qiskit_version_table\n",
    "%qiskit_copyright\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
